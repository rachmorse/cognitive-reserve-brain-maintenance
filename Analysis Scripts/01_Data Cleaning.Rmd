---
title: "data cleaning"
output: html_document
date: "2024-04-04"
---

```{r setup, include=FALSE}
if (!require("dplyr")) {
  install.packages("dplyr")
  require("dplyr")
}
if (!require("stringr")) {
  install.packages("stringr")
  require("stringr")
}
if (!require("tidyr")) {
  install.packages("tidyr")
  require("tidyr")
}
if (!require("gtools")) {
  install.packages("gtools")
  require("gtools")
}
if (!require("readr")) {
  install.packages("readr")
  require("readr")
}
if (!require("readxl")) {
  install.packages("readxl")
  require("readxl")
}
```

Note that education data is years of education and sex is coded as male=1 and female=2

Create a clean data frame for WAHA
Start with reading in the demographic and structural data for the WAHA nuts group 
```{r warning=FALSE}
# Read in the structural and demographic data
waha_df_struct <- read.csv2("/tsd/p274/data/durable/projects/p027-cr_bm/aaic/waha_nous_MRI.csv")

# Calculate total HC volume
waha_df_struct <- waha_df_struct %>%
  mutate(HIP_total = HIP_left + HIP_right)

# Rename the IDs
waha_df_struct$id <- paste("waha_", waha_df_struct$ID, sep = "")

# Read in the memory data
waha_df_dem <- read.csv2("/tsd/p274/data/durable/projects/p027-cr_bm/aaic/waha_nous_NPS.csv")

# Rename the IDs
waha_df_dem$id <- paste("waha_", waha_df_dem$ID, sep = "")

# Merge
waha_df_struct <- merge(waha_df_dem, waha_df_struct, by = c("id", "timepoint"), all = TRUE) # This keeps all participants so need to drop NAs
```

Now, read in the demographic, and structural data for the WAHA control group 
```{r warning=FALSE}
# Read in control data
waha_df_struct_controls <- read.delim("/tsd/p274/data/durable/projects/p027-cr_bm/aaic/bcn.txt", header = TRUE)

# Calculate total HC volume
waha_df_struct_controls <- waha_df_struct_controls %>%
  mutate(HIP_total = HIP_left + HIP_right)

# Rename the IDs
waha_df_struct_controls$id <- paste("waha_", waha_df_struct_controls$ID, sep = "")

# Read in control education
waha_df_edu_controls <- read.delim("/tsd/p274/data/durable/projects/p027-cr_bm/aaic/bcn_educ.txt", header = TRUE)

# Set the timeframe to 1 for all participants
waha_df_edu_controls$timepoint <- 1

# Rename the IDs
waha_df_edu_controls$id <- paste("waha_", waha_df_edu_controls$ID, sep = "")

# Merge
waha_df_struct_controls <- merge(waha_df_edu_controls, waha_df_struct_controls, by = c("id", "timepoint"), all = TRUE)

# Read in control sex
waha_df_sex_controls <- read.delim("/tsd/p274/data/durable/projects/p027-cr_bm/aaic/bcn_sex.txt", header = TRUE)

# Set the timeframe to 1 for all participants
waha_df_sex_controls$timepoint <- 1

# Rename the IDs
waha_df_sex_controls$id <- paste("waha_", waha_df_sex_controls$ID, sep = "")

# Merge
waha_df_struct_controls <- merge(waha_df_sex_controls, waha_df_struct_controls, by = c("id", "timepoint"), all = TRUE)

# Change variable to numeric for merge
waha_df_struct_controls$Visual_Memory_ROCF_Imm <- as.numeric(waha_df_struct_controls$Visual_Memory_ROCF_Imm) # Need to change to numeric for later

# Merge the two WAHA cohorts
waha_df_struct <- merge(waha_df_struct_controls, waha_df_struct, by = c(
  "id", "timepoint", "sex", "age", "education",
  "MMSE", "HIP_left", "HIP_right", "HIP_total", "ICV"
), all = TRUE)

# This gives two rows per id per timepoint if there were any NAs in either df before the merge
# So this code fill the NAs in with the data available
waha_df_struct <- waha_df_struct %>%
  group_by(id, timepoint) %>%
  fill(everything(), .direction = "downup")

# Then this removes the repeats rows
waha_df_struct <- waha_df_struct %>%
  distinct(id, timepoint, .keep_all = TRUE)

# Then this fills in any gaps in edu and sex if data is available at any timepoint
waha_df_struct <- waha_df_struct %>%
  group_by(id) %>%
  fill(sex, education, .direction = "downup")

# Rename variables
waha_df_struct <- waha_df_struct %>%
  rename(
    edu = "education",
    icv = "ICV",
    mmse = "MMSE"
  )

# Clean WAHA to only include necessary data
columns_to_keep <- c(
  "id", "timepoint",
  "sex", "age", "edu",
  "mmse", "HIP_left", "HIP_right", "HIP_total", "icv"
)

waha_df_struct <- select(waha_df_struct, all_of(columns_to_keep))
```

Read in and clean the functional WAHA data and merge it with the structural
```{r message=FALSE, warning=FALSE}
# Read in the WAHA data as a reference
waha_df_fc <- read_delim("/tsd/p274/data/durable/projects/p027-cr_bm/rsFC/WAHAFiltAndResid_Fisher-z-trans.csv",
  delim = ",", escape_double = FALSE, trim_ws = TRUE
)

# Remove str from timepoint and convert to numeric
waha_df_fc$timepoint <- as.numeric(gsub("t", "", waha_df_fc$timepoint))

# Rename ID to id
waha_df_fc <- rename(waha_df_fc, id = code)

# Rename the IDs to include waha in the id
waha_df_fc <- waha_df_fc %>%
  mutate(id = gsub("WAHA", "waha_", id))

# Subset waha_df_fc to only include necessary data
selected_cols <- c(
  "id", "timepoint",
  names(waha_df_fc)[grepl("^(dDMN|vDMN).*- (vDMN|dDMN)", names(waha_df_fc))],
  names(waha_df_fc)[grepl("^(RECN|LECN).*- (RECN|LECN)", names(waha_df_fc))],
  names(waha_df_fc)[grepl("^(AS).*- (AS)", names(waha_df_fc))]
)

# Remove duplicate column names
selected_cols <- unique(selected_cols) # because some fc pairs are in multiple networks and as saved twice

waha_df_fc <- waha_df_fc[, selected_cols]

# Rename the waha columns so they dont have a space and can be merged with all the other cohorts
cols_to_rename <- names(waha_df_fc)[grepl("^(dDMN|vDMN).*- (vDMN|dDMN)", names(waha_df_fc))]
names(waha_df_fc)[names(waha_df_fc) %in% cols_to_rename] <- gsub(" - ", "-", cols_to_rename)

cols_to_rename <- names(waha_df_fc)[grepl("^(RECN|LECN).*- (RECN|LECN)", names(waha_df_fc))]
names(waha_df_fc)[names(waha_df_fc) %in% cols_to_rename] <- gsub(" - ", "-", cols_to_rename)

cols_to_rename <- names(waha_df_fc)[grepl("^(AS).*- (AS)", names(waha_df_fc))]
names(waha_df_fc)[names(waha_df_fc) %in% cols_to_rename] <- gsub(" - ", "-", cols_to_rename)

# Merge WAHA structural and functional dfs into one

waha_df <- merge(waha_df_struct, waha_df_fc, by = c("id", "timepoint"), all = TRUE) # This keeps all participants so need to drop NAs

# Select only the tp 1 MMSE values
# Please note that MMSE now is only baseline values
waha_df <- waha_df %>%
  group_by(id) %>%
  mutate(across(starts_with("mmse"), ~ if_else(timepoint != 1, .[timepoint == 1], .)))
```

Now read in the memory data for WAHA and merge
```{r}
# Import the raw WAHA memory data
waha_mem <- read_excel("/tsd/p274/data/durable/projects/p027-cr_bm/aaic/UB_datatable_COGNITIVE[24].xlsx",
  sheet = "Test table_WAHA"
)

waha_mem <- select(waha_mem, Subject_id, "Round_ id", Visual_Memory_ROCF_Imm, Verbal_memory_RAVLT_Total, Verbal_Memory_RAVLT_delayed)

waha_mem <- waha_mem %>%
  rename(
    id = "Subject_id",
    timepoint = "Round_ id"
  )

waha_mem$timepoint <- gsub("R", "", waha_mem$timepoint)
waha_mem$timepoint <- as.numeric(waha_mem$timepoint)

# Set -9999 as  = to NA
waha_mem$Visual_Memory_ROCF_Imm[waha_mem$Visual_Memory_ROCF_Imm == -9999.0] <- NA
waha_mem$Verbal_memory_RAVLT_Total[waha_mem$Verbal_memory_RAVLT_Total == -9999.0] <- NA
waha_mem$Verbal_Memory_RAVLT_delayed[waha_mem$Verbal_Memory_RAVLT_delayed == -9999.0] <- NA

waha_mem$id <- paste0("waha_", waha_mem$id)

# Merge the memory data
waha_df <- merge(waha_mem, waha_df, by = c("id", "timepoint"), all = TRUE)

# Drop 2000 ids because they are not technically WAHA
waha_df <- waha_df[!grepl("^waha_20", waha_df$id), ]
```

Write a function to use throughout the script to convert data to wide format
```{r warning=FALSE}
wide_format <- function(data, n_timepoints, common_vars) {
  result <- NULL

  for (i in 1:n_timepoints) {
    suffix <- paste0(".", i)
    timepoint_data <- data %>%
      filter(timepoint == i) %>%
      rename_with(~ paste0(.x, suffix), -c(id, timepoint, all_of(common_vars))) %>%
      select(-starts_with("timepoint")) # Remove the timepoint column after processing

    result <- if (is.null(result)) {
      timepoint_data
    } else {
      full_join(result, timepoint_data, by = c("id", common_vars))
    }
  }

  return(result)
}
```

Clean WAHA df and reformat to wide df
```{r warning=FALSE}
# Save a copy of the df as csv before changing to wide format
write.csv(waha_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/WAHA clean raw data.csv")

# Run function to convert to wide
common_vars <- c("sex", "edu", "mmse")
waha_df <- wide_format(waha_df, 3, common_vars)
```


Create a clean df for COBRA data

Read in the memory data first
```{r message=FALSE, warning=FALSE}
cobra_mem <- read_delim("/tsd/p274/data/durable/projects/p027-cr_bm/aaic/cobra.csv",
  delim = ";", escape_double = FALSE, trim_ws = TRUE
)

# Rename the IDs
cobra_mem$id <- paste("cobra_", cobra_mem$subject_ID, sep = "") # This adds the string cobra and renames column to id

# Rename variables
cobra_mem <- cobra_mem %>%
  rename(
    edu = "education",
    mmse = "MMSE"
  )
```

Then read in the structural data 
```{r warning=FALSE}
cobra_struct <- read.csv2("/tsd/p274/data/durable/projects/p027-cr_bm/aaic/cobra_MRI.csv")

# Calculate total HC volume
cobra_struct <- cobra_struct %>%
  mutate(HIP_total = HIP_left + HIP_right)

# Rename the IDs
cobra_struct$id <- paste("cobra_", cobra_struct$subject_ID, sep = "") # This adds the string cobra and renames column to id

# Rename variables
cobra_struct <- cobra_struct %>%
  rename(icv = "ICV")

# Merge COBRA structural and mem dfs into one
cobra_struct <- merge(cobra_mem, cobra_struct, by = c("id", "timepoint"), all = TRUE)

# Clean Cobra to only include necessary data
columns_to_keep <- c(
  "id", "timepoint",
  "sex", "age", "edu",
  "mmse", "HIP_left", "HIP_right", "HIP_total", "icv",
  "EM_verbal", "EM_numerical", "EM_figural"
)

cobra_struct <- select(cobra_struct, all_of(columns_to_keep))
```

Now read in functional data and merge
```{r message=FALSE, warning=FALSE}
# Read COBRA functional data
cobra_func <- read_csv("/tsd/p274/data/durable/projects/p027-cr_bm/Umu/FC_shirer_CobraBetula/FC_Shirer90x90_Fisher-z-trans_FiltAndResid_Cobra_smallBB.csv")

# Rename id column
cobra_func <- cobra_func %>%
  rename(id = "...1")

# Add a new column to specify the timepoint
cobra_func <- cobra_func %>%
  mutate(timepoint = ifelse(grepl("y00$", id), 1,
    ifelse(grepl("y05$", id), 2, NA)
  ))

# Subset cobra_func to only include necessary data
selected_cols <- c(
  "id", "timepoint",
  names(cobra_func)[grepl("^(dDMN|vDMN).*-(vDMN|dDMN)", names(cobra_func))],
  names(cobra_func)[grepl("^(RECN|LECN).*-(RECN|LECN)", names(cobra_func))],
  names(cobra_func)[grepl("^(AS).*-(AS)", names(cobra_func))]
)

selected_cols <- unique(selected_cols) # because some fc connections are in multiple networks
cobra_func <- cobra_func[, selected_cols]

# Rename the IDs
cobra_func <- cobra_func %>%
  mutate(id = str_replace(id, "C([0-9]+)_y[0-9]+", "cobra_C\\1")) # This removes the string timepoint and adds the string cobra

# Merge COBRA structural and functional dfs into one
cobra_df <- merge(cobra_struct, cobra_func, by = c("id", "timepoint"), all = TRUE) # This keeps all participants so need to drop NAs
```

Rename variables and covert to wide format
```{r warning=FALSE}
# Save a copy of the df as csv before changing to wide format
write.csv(cobra_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Cobra clean raw data.csv")

# Select only the tp 1 MMSE values
# Please note that MMSE now is only baseline values
cobra_df <- cobra_df %>%
  group_by(id) %>%
  mutate(across(starts_with("mmse"), ~ if_else(timepoint != 1, .[timepoint == 1], .)))

# Run function to convert to wide
cobra_df <- wide_format(cobra_df, 2, common_vars)
```

Create a clean df for Betula data
Start by reading in and cleaning the structural data
```{r warning=FALSE}
# Read Betula structural data
betula_df_struct <- read_excel("/tsd/p274/data/durable/projects/p027-cr_bm/Umu/Betula_Freesurfer6_T567_long_2020-09-15_20-02-22_p027.xlsx")

# Rename variables
betula_df_struct <- betula_df_struct %>%
  rename(
    timepoint = TimePoint,
    id = SubjectId,
    HIP_left = "aseg:Left-Hippocampus(Volume_mm3)",
    HIP_right = "aseg:Right-Hippocampus(Volume_mm3)",
    icv = "aseg:EstimatedTotalIntraCranialVol.eTIV"
  )

# Calculate total HC volume
betula_df_struct <- betula_df_struct %>%
  mutate(HIP_total = HIP_left + HIP_right)

# Subset betula_df_struct to only include necessary data
columns_to_keep <- c(
  "timepoint",
  "id",
  "HIP_total", "HIP_left", "HIP_right", "icv"
)

betula_df_struct <- select(betula_df_struct, all_of(columns_to_keep))

# Rename the IDs
betula_df_struct <- betula_df_struct %>%
  mutate(id = paste0("betula_", gsub("\\.", "", sub("_T[5-7]$", "", id))))

# Change timepoint to be able to merge with other cohorts (right now they are 5-7)
betula_df_struct <- betula_df_struct %>%
  group_by(id) %>%
  mutate(timepoint = row_number())
```

Now read in the Betula functional data
```{r message=FALSE, warning=FALSE}
betula_func <- read_csv("/tsd/p274/data/durable/projects/p027-cr_bm/Umu/FC_shirer_CobraBetula/FC_Shirer90x90_Fisher-z-trans_FiltAndResid_Betula_smallBB.csv")

# Rename id column
betula_func <- betula_func %>%
  rename(id = "...1")

# Add a new column to specify the timepoint
betula_func <- betula_func %>%
  mutate(timepoint = case_when(
    grepl("T5$", id) ~ 1,
    grepl("T6$", id) ~ 2,
    grepl("T7$", id) ~ 3,
    TRUE ~ NA_real_
  ))

# Rename the IDs
betula_func <- betula_func %>%
  mutate(id = gsub("b", "B", id))

betula_func <- betula_func %>%
  mutate(id = paste0("betula_", sub("_T[5-7]$", "", id)))

# Subset betula_func to only include necessary data
selected_cols <- c(
  "id", "timepoint",
  names(betula_func)[grepl("^(dDMN|vDMN).*-(vDMN|dDMN)", names(betula_func))],
  names(betula_func)[grepl("^(RECN|LECN).*-(RECN|LECN)", names(betula_func))],
  names(betula_func)[grepl("^(AS).*-(AS)", names(betula_func))]
)

selected_cols <- unique(selected_cols) # because some fc connections are in multiple networks
betula_func <- betula_func[, selected_cols]

# Merge Betula functional and structural dfs and clean
betula_df <- merge(betula_df_struct, betula_func, by = c("id", "timepoint"), all = TRUE)
```

Read in Betula memory df 
```{r message=FALSE, warning=FALSE}
betula_em <- read_excel("/tsd/p274/data/durable/projects/p027-cr_bm/Umu/B_p027.xlsx")

# Rename variables
betula_em <- betula_em %>%
  rename(
    id = "Participant::Betula_ImAGen_T5_participated_Identifyer",
    timepoint = "test_wave",
    # age = "age_cohort_T",
    edu = "educ_T",
    mmse = "MMT::v518",
    sex = "Participant::sex"
  )

columns_to_keep <- c("id", "timepoint", "edu", "mmse", "sex", "SPT_VTCategoryCuedRecall::sptcrc", "SPT_VTCategoryCuedRecall::vtcrc", "SPT_VTFreeRecall::sptb", "SPT_VTFreeRecall::vtb")

betula_em <- select(betula_em, all_of(columns_to_keep))

# Rename the IDs
betula_em <- betula_em %>%
  mutate(id = paste0("betula_", gsub("\\.", "", sub("_T[5-7]$", "", id))))

# Change timepoint
betula_em <- betula_em %>%
  group_by(id) %>%
  mutate(timepoint = row_number())

# Recode the 'sex' variable. Currently its coded the opposite to
betula_em$sex <- recode(betula_em$sex, "2" = "male", "1" = "female")

# Merge Betula dfs into one
betula_df <- merge(betula_em, betula_df, by = c("id", "timepoint"), all = TRUE) # This keeps all participants so need to drop NAs
```

Read in Betula ages df 
```{r message=FALSE, warning=FALSE}
betula_age <- read_excel("/tsd/p274/data/durable/projects/p027-cr_bm/Umu/LB_data_tables_setup_V6_MRI-dates_2019-02-12 - KLAR.xlsx")

betula_age <- betula_age %>%
  rename(
    id = "Subject_id",
    timepoint = "SubjectRound_ id",
    age = "Fmri_Age"
  )

betula_age <- betula_age %>%
  select(id, timepoint, age)

betula_age <- betula_age %>%
  mutate(id = paste0("betula_", gsub("\\.", "", id)))

# Merge Betula dfs into one
betula_df <- merge(betula_age, betula_df, by = c("id", "timepoint"), all = TRUE)
```

Reshape the df to wide format

Note that while Betula does have three timepoints of data, we only have ages for tp1 and 2 and need to drop tp3 data. I drop it here.
```{r}
betula_df <- betula_df %>%
  subset(timepoint != 3)

# Save a copy of the df as csv before changing to wide format
write.csv(betula_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Betula clean raw data.csv")

# Select only the tp 1 MMSE values
# Please note that MMSE now is only baseline values
betula_df <- betula_df %>%
  group_by(id) %>%
  mutate(across(starts_with("mmse"), ~ if_else(timepoint != 1, .[timepoint == 1], .)))

# Run function to convert to wide
betula_df <- wide_format(betula_df, 2, common_vars)
```

Create a clean df for the Oslo data
Start by reading in the structural and memory data
```{r warning=FALSE}
oslo_struct <- read_delim("/tsd/p274/data/durable/projects/p027-cr_bm/aaic/oslo.csv",
  delim = ";", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE
)

# Rename variables
oslo_struct <- oslo_struct %>%
  rename(
    timepoint = "SubjectRound_id",
    id = "Subject_id",
    age = "Age",
    sex = "Sex",
    HIP_left = "MRI_aseg_left_hippocampus",
    HIP_right = "MRI_aseg_right_hippocampus",
    edu = "Edu_Years",
    scanner = "MRI_Scanner_id",
    icv = "MRI_aseg_estimated_total_intra_cranial_vol",
    mmse = "MMS"
  )

# Subset oslo_func to only include necessary data
columns_to_keep <- c(
  "timepoint",
  "id",
  "age",
  "sex",
  "HIP_left",
  "HIP_right",
  "CVLT_A_Total",
  "CVLT_5min_Free",
  "CVLT_30min_Free",
  "edu",
  "scanner",
  "mmse",
  "icv"
)

oslo_struct <- select(oslo_struct, all_of(columns_to_keep))

# Calculate total HC volume
oslo_struct <- oslo_struct %>%
  mutate(HIP_total = HIP_left + HIP_right)

# Rename the IDs
oslo_struct <- oslo_struct %>%
  mutate(id = paste0("oslo_", id))

# People have different edu values at different timepoints, so this method takes the first edu value and fills all timepoints with this
oslo_struct <- oslo_struct %>%
  group_by(id) %>%
  mutate(edu = first(edu))

# Drop participants with scanner ousPrisma - unclear with they are in this df - and drop participants without MRI
oslo_struct <- oslo_struct %>%
  filter(!(scanner == "ousPrisma" | scanner == "noMRI"))
```

Read in Oslo functional data and merge dfs
```{r warning=FALSE}
oslo_func <- read_delim("/tsd/p274/data/durable/projects/p027-cr_bm/UiO/results/FC_Shirer90x90_Fisher-z-trans.csv",
  delim = ",", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE
)

# Rename id
oslo_func <- oslo_func %>%
  rename(id = "...1")

# Add a new column to specify the timepoint
oslo_func <- oslo_func %>%
  mutate(timepoint = as.integer(str_extract(id, "([_1-6])$")))

# Rename the IDs
oslo_func <- oslo_func %>%
  mutate(id = paste0("oslo_", gsub("_[1-7]$", "", id)))

# Subset oslo_func to only include necessary data
selected_cols <- c(
  "id", "timepoint",
  names(oslo_func)[grepl("^(dDMN|vDMN).*-(vDMN|dDMN)", names(oslo_func))],
  names(oslo_func)[grepl("^(RECN|LECN).*-(RECN|LECN)", names(oslo_func))],
  names(betula_func)[grepl("^(AS).*-(AS)", names(betula_func))]
)

selected_cols <- unique(selected_cols) # because some fc connections are in multiple networks
oslo_func <- oslo_func[, selected_cols]

oslo_func_scanners <- read_delim("/tsd/p274/data/durable/projects/p027-cr_bm/UiO/results/subs.txt",
  delim = " ", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE, col_names = FALSE
)

oslo_func_scanners <- oslo_func_scanners %>%
  rename(
    id = "X2",
    timepoint = "X3",
    scanner = "X8"
  )

# Rename the IDs
oslo_func_scanners <- oslo_func_scanners %>%
  mutate(id = paste0("oslo_", gsub("_[1-7]$", "", id)))

# Rename the scanners to be able to merge with the other df
oslo_func_scanners <- oslo_func_scanners %>%
  mutate(scanner = ifelse(scanner %in% c("Avanto", "Skyra"), paste0("ous", scanner), scanner))

# Subset oslo_func_scanner to only include necessary data
columns_to_keep_scanner <- c(
  "timepoint",
  "id",
  "scanner"
)

oslo_func_scanners <- select(oslo_func_scanners, all_of(columns_to_keep_scanner))

# Merge the functional data
oslo_func2 <- merge(oslo_func_scanners, oslo_func, by = c("id", "timepoint"), all = TRUE) # This keeps all participants so need to drop NAs


# Merge Oslo dfs into one
oslo_df <- merge(oslo_struct, oslo_func2, by = c("id", "timepoint", "scanner"), all = TRUE) # This keeps all participants so need to drop NAs
```

Create a variable to consider the multiple MRI scanners and convert to wide format
```{r warning=FALSE}
# Edit the df to remove any timepoints where someone was scanned on a different scanner
# Some people have a different scanner for one tp so this removes that tp

# Step 1: Identify instances where a person has two scanner values at one timepoint
dupes <- oslo_df %>%
  group_by(id, timepoint) %>%
  filter(n_distinct(scanner) > 1) %>%
  ungroup()

# Step 2: From these instances, select the Skyra scanner if there's no functional data to prioritize the 3T scanner,
# and select the scanner with functional data if the functional exists (this should be Skyra for all)
filtered_dupes <- dupes %>%
  group_by(id, timepoint) %>%
  arrange(desc(!is.na("dDMN_midCC-dDMN_R_hipp")), desc(scanner == "ousSkyra")) %>%
  slice(1) %>%
  ungroup()

# Step 3: Create a new data frame with the dropped id, timepoint, scanner combinations
dropped_dupes <- anti_join(dupes, filtered_dupes, by = c("id", "timepoint", "scanner"))

# Step 4: Remove these instances from the original data
oslo_df <- oslo_df %>%
  anti_join(dropped_dupes, by = c("id", "timepoint", "scanner"))

# Save a copy of the df as csv before changing to wide format
write.csv(oslo_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Oslo clean raw data.csv")

# Select only the tp 1 MMSE values
# Please note that MMSE now is only baseline values
oslo_df <- oslo_df %>%
  group_by(id) %>%
  mutate(mmse = first(mmse))

# Run function to convert to wide
oslo_df <- wide_format(oslo_df, 6, common_vars)

# Make a df to check that the scanners are being selected correctly
oslo_df_scanners <- select(
  oslo_df,
  id, scanner.1, scanner.2, scanner.3, scanner.4, scanner.5, scanner.6
)
```

Now define the baseline values for all participants. This code chooses the first non-NA instance of the variable as baseline because some people do not have data at timepoint 1 and instead have their first data point at timepoint 2 or 3

```{r}
# Function to find the first non-NA value
get_first_non_na <- function(x) {
  return(x[which(!is.na(x))[1]])
}
# This only needs to be applied to the cohorts with more than 2 timepoints of data. It is already defined for the other cohorts

# Apply the function to each row
oslo_df$CVLT_A_Total_baseline <- apply(oslo_df[, c(paste0("CVLT_A_Total.", 1:6))], 1, get_first_non_na)
oslo_df$CVLT_5min_Free_baseline <- apply(oslo_df[, c(paste0("CVLT_5min_Free.", 1:6))], 1, get_first_non_na)
oslo_df$CVLT_30min_Free_baseline <- apply(oslo_df[, c(paste0("CVLT_30min_Free.", 1:6))], 1, get_first_non_na)

betula_df$CuedRecall_sptcrc_baseline <- apply(betula_df[, c(paste0("SPT_VTCategoryCuedRecall::sptcrc.", 1:2))], 1, get_first_non_na)
betula_df$CuedRecall_vtcrc_baseline <- apply(betula_df[, c(paste0("SPT_VTCategoryCuedRecall::vtcrc.", 1:2))], 1, get_first_non_na)
betula_df$FreeRecall_sptb_baseline <- apply(betula_df[, c(paste0("SPT_VTFreeRecall::sptb.", 1:2))], 1, get_first_non_na)
betula_df$FreeRecall_vtb_baseline <- apply(betula_df[, c(paste0("SPT_VTFreeRecall::vtb.", 1:2))], 1, get_first_non_na)

waha_df$Verbal_Memory_RAVLT_delayed_baseline <- apply(waha_df[, c(paste0("Verbal_Memory_RAVLT_delayed.", 1:3))], 1, get_first_non_na)
waha_df$Verbal_memory_RAVLT_Total_baseline <- apply(waha_df[, c(paste0("Verbal_memory_RAVLT_Total.", 1:3))], 1, get_first_non_na)
waha_df$Visual_Memory_ROCF_Imm_baseline <- apply(waha_df[, c(paste0("Visual_Memory_ROCF_Imm.", 1:3))], 1, get_first_non_na)

cobra_df$EM_numerical_baseline <- apply(cobra_df[, c(paste0("EM_numerical.", 1:2))], 1, get_first_non_na)
cobra_df$EM_figural_baseline <- apply(cobra_df[, c(paste0("EM_figural.", 1:2))], 1, get_first_non_na)
cobra_df$EM_verbal_baseline <- apply(cobra_df[, c(paste0("EM_verbal.", 1:2))], 1, get_first_non_na)
```


Now find the hippocampus and age baseline values
```{r warning=FALSE}
# Function to create columns
create_columns <- function(df) {
  # Create new columns
  df$HIP_total_baseline <- NA
  df$age_baseline <- NA

  # Iterate over each row
  for (i in 1:nrow(df)) {
    # Get the indices of the non-NA values for HIP_total and age
    hip_indices <- which(!is.na(df[i, grep("HIP_total", names(df))]))
    age_indices <- which(!is.na(df[i, grep("age", names(df))]))

    # If there's at least one non-NA value, assign it to the baseline column
    if (length(hip_indices) >= 1) {
      df$HIP_total_baseline[i] <- df[i, paste0("HIP_total.", hip_indices[1])]
    }
    if (length(age_indices) >= 1) {
      df$age_baseline[i] <- df[i, paste0("age.", age_indices[1])]
    }
  }
  return(df)
}


# Apply the function
oslo_df <- create_columns(oslo_df)
betula_df <- create_columns(betula_df)
waha_df <- create_columns(waha_df)
cobra_df <- create_columns(cobra_df)

baseline_vars <- c("HIP_total_baseline", "age_baseline")

betula_df <- betula_df %>%
  mutate_at(vars(baseline_vars), as.numeric)

waha_df <- waha_df %>%
  mutate_at(vars(baseline_vars), as.numeric)

oslo_df <- oslo_df %>%
  mutate_at(vars(baseline_vars), as.numeric)

cobra_df <- cobra_df %>%
  mutate_at(vars(baseline_vars), as.numeric)
```

Now write the data frames as CSVs
NOTE that no outliers have been removed from these dfs
```{r}
write.csv(betula_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Wide Format/Betula clean raw data wide.csv")

write.csv(waha_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Wide Format/WAHA clean raw data wide.csv")

write.csv(cobra_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Wide Format/Cobra clean raw data wide.csv")

write.csv(oslo_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Wide Format/Oslo clean raw data wide.csv")
```

Create a study variable before merging the df
```{r}
waha_df$study <- str_extract(waha_df$id, "^[a-zA-Z]+")
cobra_df$study <- str_extract(cobra_df$id, "^[a-zA-Z]+")
betula_df$study <- str_extract(betula_df$id, "^[a-zA-Z]+")

# Function to determine scanner type
determine_scanner_type <- function(scanners) {
  if ("ousAvanto" %in% scanners && "ousSkyra" %in% scanners) {
    return("oslo_mix")
  } else if ("ousAvanto" %in% scanners) {
    return("oslo_avanto")
  } else if ("ousSkyra" %in% scanners) {
    return("oslo_skyra")
  } else {
    return(NA_character_) # Return NA if no scanners
  }
}

# Apply function to each row
oslo_df <- oslo_df %>%
  rowwise() %>%
  mutate(study = determine_scanner_type(c_across(starts_with("scanner.")))) %>%
  ungroup()

# Check that its working
oslotest <- select(oslo_df, id, study, paste0("scanner.", 1:6))
```

Now exclude values that are not within 3 SD of the norm for each given variable for each study
```{r}
# Start by making a merged df
merged_cohorts <- bind_rows(waha_df, cobra_df, betula_df, oslo_df)

# Filter the max baseline age to be 60 years
merged_cohorts <- merged_cohorts %>% 
  filter(age.1 >= 60)

# Check which columns need to be excluded when removing outliers by removing the FC columns to see the data better
filtered_df <- merged_cohorts %>% select(-contains(c("RECN", "DMN", "LECN", "SN")))

# Remove columns for which data should not be removed if participants are outside of 3 SD
exclude_cols <- c(
  "id", "sex", "mmse", "edu", "study",
  "age_baseline",
  paste0("HIP_left.", 1:6), # Removing this and using only HIP_total
  paste0("HIP_right.", 1:6),
  paste0("age.", 1:6),
  paste0("scanner.", 1:6)
)

# Define a function to replace values outside 3 SD with NA
replace_outliers_with_na <- function(x) {
  mean_x <- mean(x, na.rm = TRUE)
  sd_x <- sd(x, na.rm = TRUE)
  x[abs(x - mean_x) > 3 * sd_x] <- NA
  return(x)
}

# Applying the function
cleaned_data <- merged_cohorts %>%
  group_by(study) %>% # Group by study so that 3 SD is calculated separately for each
  mutate(across(
    .cols = setdiff(names(merged_cohorts), c("study", exclude_cols)),
    .fns = ~ replace_outliers_with_na(.)
  )) %>%
  ungroup()
```


```{r}
# Create a new variable for study that does not consider scanner
cleaned_data <- cleaned_data %>%
  mutate(cohort = ifelse(study == "oslo_avanto", "Oslo",
    ifelse(study == "oslo_skyra", "Oslo",
      ifelse(study == "oslo_mix", "Oslo",
        ifelse(study == "betula", "Betula",
          ifelse(study == "waha", "WAHA",
            ifelse(study == "cobra", "Cobra", NA)
          )
        )
      )
    )
  ))

# Split the dfs again to save them
oslo_df <- cleaned_data %>%
  filter(cohort == "Oslo")

betula_df <- cleaned_data %>%
  filter(cohort == "Betula")

waha_df <- cleaned_data %>%
  filter(cohort == "WAHA")

cobra_df <- cleaned_data %>%
  filter(cohort == "Cobra")
``` 

Write new CSVs with no outliers

```{r}
write.csv(betula_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Wide Format/Betula no outliers data wide.csv")

write.csv(waha_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Wide Format/WAHA no outliers data wide.csv")

write.csv(cobra_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Wide Format/Cobra no outliers data wide.csv")

write.csv(oslo_df, file = "/tsd/p274/data/durable/projects/p027-cr_bm/Clean Data All Cohorts/Wide Format/Oslo no outliers data wide.csv")
```
